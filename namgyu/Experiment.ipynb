{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e9e775",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, datasets, transforms\n",
    "import math\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "from project import DATASETS_DIR, get_weights_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bc8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61d7f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # is this right? TODO\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680dda6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cifar_train = datasets.CIFAR10(root=DATASETS_DIR, train=True, download=True, transform=transform)\n",
    "cifar_test = datasets.CIFAR10(root=DATASETS_DIR, train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a360fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = torch.utils.data.DataLoader(cifar_train, batch_size=batch_size, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(cifar_test, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07da4cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_vgg_classifier_(model, classes=10):\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Linear(512 * 7 * 7, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, 4096),\n",
    "        nn.ReLU(True),\n",
    "        nn.Dropout(),\n",
    "        nn.Linear(4096, classes),\n",
    "    )\n",
    "    return model\n",
    "    \n",
    "def _kaiming_normal_scaled_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu', scale=1):\n",
    "    \"\"\"\n",
    "    He init with std scaled by `scale`\n",
    "    \"\"\"\n",
    "    fan = nn.init._calculate_correct_fan(tensor, mode)\n",
    "    gain = nn.init.calculate_gain(nonlinearity, a)\n",
    "    std = gain / math.sqrt(fan)\n",
    "    std *= scale\n",
    "    print(std)\n",
    "    with torch.no_grad():\n",
    "        return tensor.normal_(0, std)\n",
    "\n",
    "def reinitialize_vgg_(model, scale=1):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv2d):\n",
    "            _kaiming_normal_scaled_(m.weight, mode='fan_out', nonlinearity='relu', scale=scale)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, 0, 0.01)\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce8055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_(model, data_train, data_val, criterion, opt, scheduler=None, history=None, verbose=1):\n",
    "    \"\"\"\n",
    "    Train epoch and in-place update model and history\n",
    "    Returns\n",
    "        model, history\n",
    "    \"\"\"\n",
    "    if history is None:\n",
    "        history = defaultdict(list)\n",
    "        \n",
    "    norms = []\n",
    "    \n",
    "    for val, data in [(False, data_train), (True, data_val)]:\n",
    "        if val:\n",
    "            model.eval()\n",
    "        else:\n",
    "            model.train()\n",
    "        \n",
    "        total = 0\n",
    "        cum_loss = 0\n",
    "        cum_correct = 0\n",
    "    \n",
    "        for inputs, labels in tqdm(data) if verbose else data:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            opt.zero_grad()\n",
    "            with torch.set_grad_enabled(not val):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = outputs.max(axis=1)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                if not val:\n",
    "                    loss.backward()\n",
    "                    norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1000)\n",
    "                    norms.append(norm.item())\n",
    "                    opt.step()\n",
    "            \n",
    "            if not val and scheduler:\n",
    "                scheduler.step()\n",
    "            \n",
    "            total += inputs.size(0)\n",
    "            cum_loss += loss.item() * inputs.size(0)\n",
    "            cum_correct += torch.sum(labels == preds).item()\n",
    "        \n",
    "        if val:\n",
    "            history[\"val_acc\"].append(cum_correct / total)\n",
    "            history[\"val_loss\"].append(cum_loss / total)\n",
    "        else:\n",
    "            history[\"train_acc\"].append(cum_correct / total)\n",
    "            history[\"train_loss\"].append(cum_loss / total)\n",
    "    \n",
    "    print(\" GRAD NORMS \".center(80, \"#\"))\n",
    "    print(pd.Series(norms).describe())\n",
    "    \n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d41e065",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = 5\n",
    "print(\"Rescaling VGG conv weights by {}\".format(scale))\n",
    "model = models.vgg11()\n",
    "replace_vgg_classifier_(model, classes=10)\n",
    "reinitialize_vgg_(model, scale=scale)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ae4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.SGD(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d09124b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "history = None\n",
    "epochs = 500\n",
    "save_interval = 20\n",
    "weights_dir = \"weights\"\n",
    "for e in range(epochs):\n",
    "    elapsed = time.time() - start\n",
    "    s = elapsed % 60\n",
    "    m = elapsed // 60 % 60\n",
    "    h = elapsed // 3600\n",
    "    print(\"Epoch {:04d}\".format(e + 1), end=\"\")\n",
    "    print(\" | {:02.0f}:{:02.0f}:{:02.0f}\".format(h, m, s), end=\"\")\n",
    "    print(\" | \", end=\"\")\n",
    "    model, history = train_epoch_(model, train, test, opt=opt, criterion=criterion, history=history, verbose=False)\n",
    "    print({k[:7]: \"{:.4f}\".format(v[-1]) for k, v in history.items()})\n",
    "    \n",
    "    if (e + 1) % save_interval == 0:\n",
    "        path = os.path.join(weights_dir, \"vgg_weights_e{:04d}.pth\".format(e))\n",
    "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "        torch.save(model.state_dict(), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
